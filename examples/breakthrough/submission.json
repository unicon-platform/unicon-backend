{
    "user_inputs": [
      {
        "task_id": 1,
        "user_input": [
          {
            "id": "DATA.IN.AGENT.0",
            "data": {
              "file_name": "agent_1.py",
              "content": "import json\n\nimport utils\n\nimport time\n\n\nclass PlayerAI:\n    def __init__(self):\n        self.table = {}\n\n        self.heuristic_cache = {}\n\n        self.timer = None\n\n    def board_to_key(self, board, is_max_move=True):\n        black = 0\n\n        white = 0\n\n        for i in range(6):\n            for j in range(6):\n                index = i * 6 + j\n\n                if board[i][j] == 'B':\n                    black |= 1 << index\n\n                elif board[i][j] == 'W':\n                    white |= 1 << index\n\n        return (black, white, is_max_move)\n\n    def make_move(self, board):\n        '''\n\n        This is the function that will be called from main.py\n\n        Your function should implement a minimax algorithm with\n\n        alpha beta pruning to select the appropriate move based\n\n        on the input board state. Play for black.\n\n        Parameters\n\n        ----------\n\n        self: object instance itself, passed in automatically by Python\n\n        board: 2D list-of-lists\n\n        Contains characters 'B', 'W', and '_' representing\n\n        Black pawns, White pawns and empty cells respectively\n\n        Returns\n\n        -------\n\n        Two lists of coordinates [row_index, col_index]\n\n        The first list contains the source position of the Black pawn\n\n        to be moved, the second list contains the destination position\n\n        '''\n\n        ################\n\n        # Starter code #\n\n        ################\n\n        # TODO: Replace starter code with your AI\n\n        self.timer = time.time()\n\n        return list(map(list, self.minimax(board)[0]))\n\n    def available_moves(self, board):\n        moves = []\n\n        for r in range(len(board) - 1, -1, -1):\n            for c in range(len(board[r])):\n                # check if B can move forward directly\n\n                if board[r][c] == 'B':\n                    if c and board[r + 1][c - 1] != 'B':\n                        moves.append(((r, c), (r + 1, c - 1)))\n\n                    if c != len(board[r]) - 1 and board[r + 1][c + 1] != 'B':\n                        moves.append(((r, c), (r + 1, c + 1)))\n\n                    if board[r + 1][c] == '_':\n                        moves.append(((r, c), (r + 1, c)))\n\n        return moves\n\n    def minimax(\n        self, board, alpha=float('-inf'), beta=float('inf'), is_max_node=True, cutoff_depth=5\n    ):\n        '''returns a [action, value]'''\n\n        actions = self.available_moves(board)\n\n        if cutoff_depth == 0 or utils.is_game_over(board):\n            av = [actions[0], self.heuristic(board) if is_max_node else -self.heuristic(board)]\n\n            return av\n\n        av = [actions[0], float('-inf') if is_max_node else float('inf')]\n\n        for action in actions:\n            if time.time() - self.timer > 2.9:\n                break\n\n            fro, to = action\n\n            new_board = utils.state_change(board, fro, to, in_place=False)\n\n            utils.invert_board(new_board, in_place=True)\n\n            # memoise - do not explore nodes deemed cmi by transposition table\n\n            if av[0][0] is not None and self.board_to_key(new_board, not is_max_node) in self.table:\n                memo_alpha, memo_beta, memo_v, memo_action = self.table[\n                    self.board_to_key(new_board, not is_max_node)\n                ]\n\n                if is_max_node:\n                    if memo_v <= alpha:\n                        continue\n\n                else:\n                    if memo_v >= beta:\n                        continue\n\n            current_value = self.minimax(\n                new_board, alpha, beta, is_max_node=not is_max_node, cutoff_depth=cutoff_depth - 1\n            )[1]\n\n            # pick min or max\n\n            if not av[0][0]:\n                av = (action, current_value)\n\n            elif is_max_node:\n                if av[1] < current_value:\n                    av = (action, current_value)\n\n            else:\n                if av[1] > current_value:\n                    av = (action, current_value)\n\n            # update alpha or beta\n\n            if is_max_node:\n                alpha = max(alpha, current_value)\n\n            else:\n                beta = min(beta, current_value)\n\n            # pruning. no point anymore\n\n            if beta <= alpha:\n                if av[1] not in [float('inf'), float('-inf')]:\n                    self.table[self.board_to_key(board, is_max_node)] = (alpha, beta, av[1], av[0])\n\n                return av\n\n        if av[1] not in [float('inf'), float('-inf')]:\n            self.table[self.board_to_key(board, is_max_node)] = (alpha, beta, av[1], av[0])\n\n        return av\n\n    def heuristic(self, board):\n        if 'B' in board[-1]:\n            return float('inf')\n\n        if 'W' in board[0]:\n            return float('-inf')\n\n        key = self.board_to_key(board)\n\n        if key in self.heuristic_cache:\n            return self.heuristic_cache[key]\n\n        inverted = utils.invert_board(board, in_place=False)\n\n        res = sum([self.get_piece_value(board, i, j) for i in range(6) for j in range(6)]) - sum(\n            [self.get_piece_value(inverted, i, j) for i in range(6) for j in range(6)]\n        )\n\n        self.heuristic_cache[key] = res\n\n        return res\n\n    def read(self, board, i, j):\n        return board[i][j] if 0 <= i < 6 and 0 <= j < 6 else None\n\n    # only black piece\n\n    def get_piece_value(self, board, i, j):\n        if board[i][j] != 'B':\n            return 0\n\n        DANGER_VALUE = 5\n\n        HIGH_DANGER_VALUE = 100\n\n        TOGETHER_VALUE = 8\n\n        def MOBILITY_VALUE(i):\n            return 10 if i == 3 else 0\n\n        # piece danger value\n\n        # the +200 is because i realise my pawns have the tendency to suicide into blocks\n\n        piece_danger_value = i * DANGER_VALUE + 200\n\n        piece_high_danger_value = HIGH_DANGER_VALUE if i == 4 else 0\n\n        connection_horizontal_value = (\n            (self.read(board, i, j - 1) == 'B') + (self.read(board, i, j + 1) == 'B')\n        ) * TOGETHER_VALUE\n\n        connection_vertical_value = (\n            (self.read(board, i - 1, j) == 'B') + (self.read(board, i + 1, j) == 'B')\n        ) * TOGETHER_VALUE\n\n        # piece mobility value\n\n        piece_mobility_value = MOBILITY_VALUE(\n            sum(\n                [\n                    self.read(board, i + 1, j - 1) in ('W', ' '),\n                    self.read(board, i + 1, j) == 'W',\n                    self.read(board, i + 1, j + 1) in ('W', ' '),\n                ]\n            )\n        )\n\n        # home ground value (i kind of like those 2 spots in particular as they defend 66% of all the high danger squares)\n\n        home_ground_value = (25 if j in [1, 4] else 15) if i == 0 else 0\n\n        return (\n            piece_danger_value\n            + connection_horizontal_value\n            + connection_vertical_value\n            + piece_high_danger_value\n            + piece_mobility_value\n            + home_ground_value\n        )\n\n\ndef make_move(*args, **kwargs):\n    return PlayerAI().make_move(*args, **kwargs)\n"
            }
          },
          {
            "id": "DATA.IN.AGENT.1",
            "data": {
              "file_name": "agent_2.py",
              "content": "import json\n\nimport utils\n\nimport time\n\n\nclass PlayerAI:\n    def __init__(self):\n        self.table = {}\n\n        self.heuristic_cache = {}\n\n        self.timer = None\n\n    def board_to_key(self, board, is_max_move=True):\n        black = 0\n\n        white = 0\n\n        for i in range(6):\n            for j in range(6):\n                index = i * 6 + j\n\n                if board[i][j] == 'B':\n                    black |= 1 << index\n\n                elif board[i][j] == 'W':\n                    white |= 1 << index\n\n        return (black, white, is_max_move)\n\n    def make_move(self, board):\n        '''\n\n        This is the function that will be called from main.py\n\n        Your function should implement a minimax algorithm with\n\n        alpha beta pruning to select the appropriate move based\n\n        on the input board state. Play for black.\n\n        Parameters\n\n        ----------\n\n        self: object instance itself, passed in automatically by Python\n\n        board: 2D list-of-lists\n\n        Contains characters 'B', 'W', and '_' representing\n\n        Black pawns, White pawns and empty cells respectively\n\n        Returns\n\n        -------\n\n        Two lists of coordinates [row_index, col_index]\n\n        The first list contains the source position of the Black pawn\n\n        to be moved, the second list contains the destination position\n\n        '''\n\n        ################\n\n        # Starter code #\n\n        ################\n\n        # TODO: Replace starter code with your AI\n\n        self.timer = time.time()\n\n        return list(map(list, self.minimax(board)[0]))\n\n    def available_moves(self, board):\n        moves = []\n\n        for r in range(len(board) - 1, -1, -1):\n            for c in range(len(board[r])):\n                # check if B can move forward directly\n\n                if board[r][c] == 'B':\n                    if c and board[r + 1][c - 1] != 'B':\n                        moves.append(((r, c), (r + 1, c - 1)))\n\n                    if c != len(board[r]) - 1 and board[r + 1][c + 1] != 'B':\n                        moves.append(((r, c), (r + 1, c + 1)))\n\n                    if board[r + 1][c] == '_':\n                        moves.append(((r, c), (r + 1, c)))\n\n        return moves\n\n    def minimax(\n        self, board, alpha=float('-inf'), beta=float('inf'), is_max_node=True, cutoff_depth=5\n    ):\n        '''returns a [action, value]'''\n\n        actions = self.available_moves(board)\n\n        if cutoff_depth == 0 or utils.is_game_over(board):\n            av = [actions[0], self.heuristic(board) if is_max_node else -self.heuristic(board)]\n\n            return av\n\n        av = [actions[0], float('-inf') if is_max_node else float('inf')]\n\n        for action in actions:\n            if time.time() - self.timer > 2.9:\n                break\n\n            fro, to = action\n\n            new_board = utils.state_change(board, fro, to, in_place=False)\n\n            utils.invert_board(new_board, in_place=True)\n\n            # memoise - do not explore nodes deemed cmi by transposition table\n\n            if av[0][0] is not None and self.board_to_key(new_board, not is_max_node) in self.table:\n                memo_alpha, memo_beta, memo_v, memo_action = self.table[\n                    self.board_to_key(new_board, not is_max_node)\n                ]\n\n                if is_max_node:\n                    if memo_v <= alpha:\n                        continue\n\n                else:\n                    if memo_v >= beta:\n                        continue\n\n            current_value = self.minimax(\n                new_board, alpha, beta, is_max_node=not is_max_node, cutoff_depth=cutoff_depth - 1\n            )[1]\n\n            # pick min or max\n\n            if not av[0][0]:\n                av = (action, current_value)\n\n            elif is_max_node:\n                if av[1] < current_value:\n                    av = (action, current_value)\n\n            else:\n                if av[1] > current_value:\n                    av = (action, current_value)\n\n            # update alpha or beta\n\n            if is_max_node:\n                alpha = max(alpha, current_value)\n\n            else:\n                beta = min(beta, current_value)\n\n            # pruning. no point anymore\n\n            if beta <= alpha:\n                if av[1] not in [float('inf'), float('-inf')]:\n                    self.table[self.board_to_key(board, is_max_node)] = (alpha, beta, av[1], av[0])\n\n                return av\n\n        if av[1] not in [float('inf'), float('-inf')]:\n            self.table[self.board_to_key(board, is_max_node)] = (alpha, beta, av[1], av[0])\n\n        return av\n\n    def heuristic(self, board):\n        if 'B' in board[-1]:\n            return float('inf')\n\n        if 'W' in board[0]:\n            return float('-inf')\n\n        key = self.board_to_key(board)\n\n        if key in self.heuristic_cache:\n            return self.heuristic_cache[key]\n\n        inverted = utils.invert_board(board, in_place=False)\n\n        res = sum([self.get_piece_value(board, i, j) for i in range(6) for j in range(6)]) - sum(\n            [self.get_piece_value(inverted, i, j) for i in range(6) for j in range(6)]\n        )\n\n        self.heuristic_cache[key] = res\n\n        return res\n\n    def read(self, board, i, j):\n        return board[i][j] if 0 <= i < 6 and 0 <= j < 6 else None\n\n    # only black piece\n\n    def get_piece_value(self, board, i, j):\n        if board[i][j] != 'B':\n            return 0\n\n        DANGER_VALUE = 5\n\n        HIGH_DANGER_VALUE = 100\n\n        TOGETHER_VALUE = 8\n\n        def MOBILITY_VALUE(i):\n            return 10 if i == 3 else 0\n\n        # piece danger value\n\n        # the +200 is because i realise my pawns have the tendency to suicide into blocks\n\n        piece_danger_value = i * DANGER_VALUE + 200\n\n        piece_high_danger_value = HIGH_DANGER_VALUE if i == 4 else 0\n\n        connection_horizontal_value = (\n            (self.read(board, i, j - 1) == 'B') + (self.read(board, i, j + 1) == 'B')\n        ) * TOGETHER_VALUE\n\n        connection_vertical_value = (\n            (self.read(board, i - 1, j) == 'B') + (self.read(board, i + 1, j) == 'B')\n        ) * TOGETHER_VALUE\n\n        # piece mobility value\n\n        piece_mobility_value = MOBILITY_VALUE(\n            sum(\n                [\n                    self.read(board, i + 1, j - 1) in ('W', ' '),\n                    self.read(board, i + 1, j) == 'W',\n                    self.read(board, i + 1, j + 1) in ('W', ' '),\n                ]\n            )\n        )\n\n        # home ground value (i kind of like those 2 spots in particular as they defend 66% of all the high danger squares)\n\n        home_ground_value = (25 if j in [1, 4] else 15) if i == 0 else 0\n\n        return (\n            piece_danger_value\n            + connection_horizontal_value\n            + connection_vertical_value\n            + piece_high_danger_value\n            + piece_mobility_value\n            + home_ground_value\n        )\n\n\ndef make_move(*args, **kwargs):\n    return PlayerAI().make_move(*args, **kwargs)\n"
            }
          }
        ]
      }
    ],
    "expected_answers": []
  }
  